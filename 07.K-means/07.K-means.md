## K-means算法 ##

聚类(clustering) 属于非监督学习 (unsupervised learning)无类别标记(class label)，例如：

![](https://i.imgur.com/WkOwz82.jpg)

需要将上图的三类点区分开，这里没有预先设定好的标签。

### 1.K-means 算法介绍 ###

- Clustering 中的经典算法，数据挖掘十大经典算法之一
- 算法接受参数 k ；然后将事先输入的n个数据对象划分为 k个聚类以便使得所获得的聚类满足：同一聚类中的对象相似度较高；而不同聚类中的对象相似度较小。
- 算法思想：以空间中k个点为中心进行聚类，对最靠近他们的对象归类。通过迭代的方法，逐次更新各聚类中心的值，直至得到最好的聚类结果
- 算法描述：
          
          （1）适当选择c个类的初始中心；
          （2）在第k次迭代中，对任意一个样本，求其到c各中心的距离，将该样本归到距离最短的中心所在     
                  的类；
          （3）利用均值等方法更新该类的中心值；
          （4）对于所有的c个聚类中心，如果利用（2）（3）的迭代法更新后，值保持不变，则迭代结束，
                   否则继续迭代。

- 算法流程：

 输入：k, data[n]

          （1） 选择k个初始中心点，例如c[0]=data[0],…c[k-1]=data[k-1];
          （2） 对于data[0]….data[n], 分别与c[0]…c[k-1]比较，假定与c[i]差值最少，就标记为i;
          （3） 对于所有标记为i点，重新计算c[i]={ 所有标记为i的data[j]之和}/标记为i的个数；
          （4） 重复(2)(3),直到所有c[i]值的变化小于给定阈值。

![](https://i.imgur.com/hW76dvD.png)

### 2.案例 ###

如下图所示：

![](https://i.imgur.com/jZvZej1.png)

现在又四种类型的药，这里只有X（weight index）和Y（pH）两种特征向量，需要将这四种药物分开，这四种药物在坐标系中的位置如下：

![](https://i.imgur.com/yDe1j0h.png)

现在假设点(1, 1)和(2, 1)为两类药物的中心点，于是有：

四个点：

![](https://i.imgur.com/LNvlSOh.png)

距离两类中心点的距离如下：

![](https://i.imgur.com/V3P59Z1.png)

从矩阵的第一行可以看出，A点距离自身距离为0，其他三个点距离A点都有一定长度，于是这里简单判定A和B、C、D是两类点，姑且认为B、C和D为一类。于是有：

![](https://i.imgur.com/3BUfxsr.png)

所以现在需要继续将B、C和D分开，这里计算三个点的中心点坐标：

C = (（2 + 4 + 5)/3 , (1 + 3 + 4)/3) = (11/3, 8/3)

如下图所示：

![](https://i.imgur.com/1MSdRrB.png)

于是用上面同样的方法来计算各个点距离两类中心点的距离：

![](https://i.imgur.com/qdF2nwx.png)

从上面可见，B距离第一类中心点A距离比距离C (11/3, 8/3)要近，而C和D却相反，所以这里可以将B和A归为一类，C和D为一类，于是有：

![](https://i.imgur.com/sMpiBCu.png)

现在计算根据分类情况计算新的中心点，便于进一步区分：

- 对于第一类A和B，有 C1 = ((1 + 2)/2, (1 + 1)/2) = (3/2, 1)
- 对于第二类C和D，有 C2 = ((4 + 5)/2, (3 + 4)/2) = (9/2, 7/2)

于是有：

![](https://i.imgur.com/Y6i9ukJ.png)

同样地，四个点分别计算距离新的两个中心点的距离：

![](https://i.imgur.com/viGDU9n.png)

从上面可见，A和B距离第一类新中心点(3/2, 1)距离比第二类(9/2, 7/2)要近，而C和D则相反，于是有：

![](https://i.imgur.com/C9tUowB.png)

和上面一次分类一样，A和B被分为一类，C和D分为一类，再计算中心点已经没有意义了，所以算法在这里停止了，分类结束。
